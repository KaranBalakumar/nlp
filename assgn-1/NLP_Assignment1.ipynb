{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgEToFFecWZr",
        "outputId": "5dc7e42f-b171-4e71-8afc-06265fcca824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "7-YVHRn6_FwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "import math\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# -----------------------\n",
        "# Step 1: Dataset Loader\n",
        "# -----------------------\n",
        "def load_dataset(filepath):\n",
        "    data = []\n",
        "    current_label = None\n",
        "    current_text = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"'\") and line.count(\"','\") >= 1:\n",
        "                if current_label is not None:\n",
        "                    data.append((current_label, \" \".join(current_text)))\n",
        "                parts = line.split(\"','\", 1)\n",
        "                current_label = parts[0].strip(\"'\")\n",
        "                current_text = [parts[1].rstrip(\"'\")] if len(parts) > 1 else []\n",
        "            else:\n",
        "                current_text.append(line)\n",
        "        if current_label is not None:\n",
        "            data.append((current_label, \" \".join(current_text)))\n",
        "    return zip(*data)  # returns (labels, texts)\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", str(text).lower())\n",
        "\n",
        "# -----------------------\n",
        "# Step 2: N-gram Language Model (Better Version)\n",
        "# -----------------------\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, n=2):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "        self.context_counts = defaultdict(int)\n",
        "        self.vocab = set()\n",
        "\n",
        "    def train(self, texts):\n",
        "        for s in texts:\n",
        "            tokens = [\"<s>\"] + tokenize_text(s) + [\"</s>\"]\n",
        "            self.vocab.update(tokens)\n",
        "            for i in range(len(tokens) - self.n + 1):\n",
        "                ngram = tuple(tokens[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                self.ngram_counts[ngram] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        context = ngram[:-1]\n",
        "        V = len(self.vocab)\n",
        "        return (self.ngram_counts[ngram] + 1) / (self.context_counts[context] + V)\n",
        "\n",
        "    def perplexity(self, texts):\n",
        "        N, log_prob_sum = 0, 0.0\n",
        "        V = len(self.vocab)\n",
        "        for s in texts:\n",
        "            tokens = [\"<s>\"] * (self.n - 1) + tokenize_text(s) + [\"</s>\"]\n",
        "            for i in range(len(tokens) - self.n + 1):\n",
        "                ngram = tuple(tokens[i:i+self.n])\n",
        "                p = self.prob(ngram)\n",
        "                log_prob_sum += math.log(p, 2)\n",
        "                N += 1\n",
        "        return math.pow(2, -log_prob_sum / N)\n",
        "\n",
        "# -----------------------\n",
        "# Step 3: Extrinsic Classification\n",
        "# -----------------------\n",
        "def extrinsic_classification(train_texts, train_labels, test_texts, test_labels, n=1, method=\"nb\"):\n",
        "    # Join tokens into sentences\n",
        "    train_sentences = [\" \".join(tokenize_text(t)) for t in train_texts]\n",
        "    test_sentences = [\" \".join(tokenize_text(t)) for t in test_texts]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, n), max_features=8000)\n",
        "    X_train = vectorizer.fit_transform(train_sentences)\n",
        "    X_test = vectorizer.transform(test_sentences)\n",
        "\n",
        "    if method == \"nb\":\n",
        "        clf = MultinomialNB()\n",
        "    else:\n",
        "        clf = LinearSVC(class_weight=\"balanced\")\n",
        "\n",
        "    clf.fit(X_train, train_labels)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(test_labels, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        test_labels, y_pred, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    return acc, precision, recall, f1\n",
        "\n",
        "# -----------------------\n",
        "# Step 4: Run Experiments\n",
        "# -----------------------\n",
        "def run_experiment(train_path, test_path, lang=\"English\", method=\"nb\"):\n",
        "    print(f\"\\n===== {lang} Dataset =====\")\n",
        "    train_labels, train_texts = load_dataset(train_path)\n",
        "    test_labels, test_texts = load_dataset(test_path)\n",
        "\n",
        "    results = []\n",
        "    for n in [1, 2, 3]:\n",
        "        print(f\"\\n=== Training {n}-gram Model ===\")\n",
        "        model = NGramLanguageModel(n=n)\n",
        "        model.train(train_texts)\n",
        "        ppl = model.perplexity(test_texts)\n",
        "        print(f\"Perplexity: {ppl:.2f}\")\n",
        "\n",
        "        acc, precision, recall, f1 = extrinsic_classification(\n",
        "            train_texts, train_labels, test_texts, test_labels, n=n, method=method\n",
        "        )\n",
        "        print(f\"Classification - Acc: {acc:.3f}, Prec: {precision:.3f}, Rec: {recall:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "        results.append({\n",
        "            \"n\": n,\n",
        "            \"perplexity\": ppl,\n",
        "            \"accuracy\": acc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# -----------------------\n",
        "# Step 5: Paths & Execution\n",
        "# -----------------------\n",
        "eng_train = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_15000.txt\"\n",
        "eng_test = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_test.txt\"\n",
        "\n",
        "hin_train = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_15000.txt\"\n",
        "hin_test = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_test.txt\"\n",
        "\n",
        "eng_results = run_experiment(eng_train, eng_test, lang=\"English\", method=\"nb\")\n",
        "hin_results = run_experiment(hin_train, hin_test, lang=\"Hindi\", method=\"nb\")\n",
        "\n",
        "print(\"\\nFinal English Results:\", eng_results)\n",
        "print(\"\\nFinal Hindi Results:\", hin_results)\n",
        "\n",
        "# Step 5: Paths & Execution\n",
        "# -----------------------\n",
        "eng_train = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_30000.txt\"\n",
        "eng_test = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_test.txt\"\n",
        "\n",
        "hin_train = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_30000.txt\"\n",
        "hin_test = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_test.txt\"\n",
        "\n",
        "eng_results = run_experiment(eng_train, eng_test, lang=\"English\", method=\"nb\")\n",
        "hin_results = run_experiment(hin_train, hin_test, lang=\"Hindi\", method=\"nb\")\n",
        "\n",
        "print(\"\\nFinal English Results:\", eng_results)\n",
        "print(\"\\nFinal Hindi Results:\", hin_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9WJwFQnFXHz",
        "outputId": "78a3001f-780c-44a5-cd97-3fa25ddd32a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== English Dataset =====\n",
            "\n",
            "=== Training 1-gram Model ===\n",
            "Perplexity: 1546.14\n",
            "Classification - Acc: 0.385, Prec: 0.345, Rec: 0.385, F1: 0.267\n",
            "\n",
            "=== Training 2-gram Model ===\n",
            "Perplexity: 3188.66\n",
            "Classification - Acc: 0.397, Prec: 0.374, Rec: 0.397, F1: 0.289\n",
            "\n",
            "=== Training 3-gram Model ===\n",
            "Perplexity: 18522.60\n",
            "Classification - Acc: 0.397, Prec: 0.376, Rec: 0.397, F1: 0.291\n",
            "\n",
            "===== Hindi Dataset =====\n",
            "\n",
            "=== Training 1-gram Model ===\n",
            "Perplexity: 96.20\n",
            "Classification - Acc: 0.561, Prec: 0.557, Rec: 0.561, F1: 0.501\n",
            "\n",
            "=== Training 2-gram Model ===\n",
            "Perplexity: 63.13\n",
            "Classification - Acc: 0.612, Prec: 0.662, Rec: 0.612, F1: 0.570\n",
            "\n",
            "=== Training 3-gram Model ===\n",
            "Perplexity: 127.02\n",
            "Classification - Acc: 0.609, Prec: 0.661, Rec: 0.609, F1: 0.568\n",
            "\n",
            "Final English Results: [{'n': 1, 'perplexity': 1546.1389210910268, 'accuracy': 0.38467847769028873, 'precision': 0.34457367014386314, 'recall': 0.38467847769028873, 'f1': 0.26680545877976924}, {'n': 2, 'perplexity': 3188.6590699666626, 'accuracy': 0.3971456692913386, 'precision': 0.37439754965577104, 'recall': 0.3971456692913386, 'f1': 0.288610861702526}, {'n': 3, 'perplexity': 18522.599143233747, 'accuracy': 0.3971456692913386, 'precision': 0.3756440795327803, 'recall': 0.3971456692913386, 'f1': 0.29076014685879703}]\n",
            "\n",
            "Final Hindi Results: [{'n': 1, 'perplexity': 96.20178195662183, 'accuracy': 0.5612, 'precision': 0.556970114713122, 'recall': 0.5612, 'f1': 0.5009851438766234}, {'n': 2, 'perplexity': 63.13048489745364, 'accuracy': 0.6122, 'precision': 0.661792484366388, 'recall': 0.6122, 'f1': 0.5698069983406172}, {'n': 3, 'perplexity': 127.01870775657082, 'accuracy': 0.6089333333333333, 'precision': 0.6611290754704524, 'recall': 0.6089333333333333, 'f1': 0.5675089955368896}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# -----------------------\n",
        "# Step 1: Dataset Loader\n",
        "# -----------------------\n",
        "def load_dataset(filepath):\n",
        "    data = []\n",
        "    current_label = None\n",
        "    current_text = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"'\") and line.count(\"','\") >= 1:\n",
        "                if current_label is not None:\n",
        "                    data.append((current_label, \" \".join(current_text)))\n",
        "                parts = line.split(\"','\", 1)\n",
        "                current_label = parts[0].strip(\"'\")\n",
        "                current_text = [parts[1].rstrip(\"'\")] if len(parts) > 1 else []\n",
        "            else:\n",
        "                current_text.append(line)\n",
        "        if current_label is not None:\n",
        "            data.append((current_label, \" \".join(current_text)))\n",
        "    return zip(*data)  # returns (labels, texts)\n",
        "\n",
        "def tokenize_text(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", str(text).lower())\n",
        "\n",
        "# -----------------------\n",
        "# Step 2: N-gram Language Model\n",
        "# -----------------------\n",
        "class NGramLanguageModel:\n",
        "    def __init__(self, n=2):\n",
        "        self.n = n\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "        self.context_counts = defaultdict(int)\n",
        "        self.vocab = set()\n",
        "\n",
        "    def train(self, texts):\n",
        "        for s in texts:\n",
        "            tokens = [\"<s>\"] + tokenize_text(s) + [\"</s>\"]\n",
        "            self.vocab.update(tokens)\n",
        "            for i in range(len(tokens) - self.n + 1):\n",
        "                ngram = tuple(tokens[i:i+self.n])\n",
        "                context = ngram[:-1]\n",
        "                self.ngram_counts[ngram] += 1\n",
        "                self.context_counts[context] += 1\n",
        "\n",
        "    def prob(self, ngram):\n",
        "        context = ngram[:-1]\n",
        "        V = len(self.vocab)\n",
        "        return (self.ngram_counts[ngram] + 1) / (self.context_counts[context] + V)\n",
        "\n",
        "    def perplexity(self, texts):\n",
        "        N, log_prob_sum = 0, 0.0\n",
        "        for s in texts:\n",
        "            tokens = [\"<s>\"] * (self.n - 1) + tokenize_text(s) + [\"</s>\"]\n",
        "            for i in range(len(tokens) - self.n + 1):\n",
        "                ngram = tuple(tokens[i:i+self.n])\n",
        "                p = self.prob(ngram)\n",
        "                log_prob_sum += math.log(p, 2)\n",
        "                N += 1\n",
        "        return math.pow(2, -log_prob_sum / N)\n",
        "\n",
        "# -----------------------\n",
        "# Step 3: Save/Load Models\n",
        "# -----------------------\n",
        "def save_model(obj, filepath):\n",
        "    with open(filepath, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_model(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# -----------------------\n",
        "# Step 4: Train & Save Bigram + Classifier\n",
        "# -----------------------\n",
        "def train_and_save(train_path, test_path, lang, size, method=\"nb\"):\n",
        "    print(f\"\\n===== Training {lang} {size} Dataset (Bigram) =====\")\n",
        "    train_labels, train_texts = load_dataset(train_path)\n",
        "    test_labels, test_texts = load_dataset(test_path)\n",
        "\n",
        "    # Train N-gram LM\n",
        "    lm = NGramLanguageModel(n=2)\n",
        "    lm.train(train_texts)\n",
        "    ppl = lm.perplexity(test_texts)\n",
        "\n",
        "    # Extrinsic classification\n",
        "    train_sentences = [\" \".join(tokenize_text(t)) for t in train_texts]\n",
        "    test_sentences = [\" \".join(tokenize_text(t)) for t in test_texts]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=8000)\n",
        "    X_train = vectorizer.fit_transform(train_sentences)\n",
        "    X_test = vectorizer.transform(test_sentences)\n",
        "\n",
        "    if method == \"nb\":\n",
        "        clf = MultinomialNB()\n",
        "    else:\n",
        "        clf = LinearSVC(class_weight=\"balanced\")\n",
        "\n",
        "    clf.fit(X_train, train_labels)\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(test_labels, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        test_labels, y_pred, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "\n",
        "    print(f\"Perplexity: {ppl:.2f}\")\n",
        "    print(f\"Classification - Acc: {acc:.3f}, Prec: {precision:.3f}, Rec: {recall:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "    # ✅ Save into your folder\n",
        "    save_path = f\"/content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_{lang.lower()}_{size}.pkl\"\n",
        "    save_model({\n",
        "        \"lm\": lm,\n",
        "        \"vectorizer\": vectorizer,\n",
        "        \"classifier\": clf,\n",
        "        \"labels\": sorted(list(set(train_labels)))\n",
        "    }, save_path)\n",
        "    print(f\"Model saved at {save_path}\")\n",
        "\n",
        "    return {\n",
        "        \"lang\": lang, \"size\": size,\n",
        "        \"perplexity\": ppl, \"accuracy\": acc,\n",
        "        \"precision\": precision, \"recall\": recall, \"f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# Step 5: Predict Genre (Top-k)\n",
        "# -----------------------\n",
        "def predict_genre(paragraph, model_path, top_k=3):\n",
        "    saved = load_model(model_path)\n",
        "    vectorizer = saved[\"vectorizer\"]\n",
        "    clf = saved[\"classifier\"]\n",
        "\n",
        "    tokens = \" \".join(tokenize_text(paragraph))\n",
        "    X = vectorizer.transform([tokens])\n",
        "\n",
        "    if hasattr(clf, \"predict_proba\"):  # works for Naive Bayes\n",
        "        probs = clf.predict_proba(X)[0]\n",
        "        classes = clf.classes_\n",
        "    else:  # fallback for models without predict_proba (like LinearSVC)\n",
        "        if hasattr(clf, \"decision_function\"):\n",
        "            scores = clf.decision_function(X)\n",
        "            if scores.ndim == 1:\n",
        "                probs = np.exp(scores) / np.sum(np.exp(scores))\n",
        "            else:\n",
        "                probs = np.exp(scores[0]) / np.sum(np.exp(scores[0]))\n",
        "            classes = clf.classes_\n",
        "        else:\n",
        "            return [(clf.predict(X)[0], 1.0)]  # single prediction only\n",
        "\n",
        "    top_idx = np.argsort(probs)[::-1][:top_k]\n",
        "    return [(classes[i], float(probs[i])) for i in top_idx]\n",
        "\n",
        "# -----------------------\n",
        "# Example Execution\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    eng_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_2500.txt\"\n",
        "    eng_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_15000.txt\"\n",
        "    eng_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_30000.txt\"\n",
        "    eng_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_test.txt\"\n",
        "\n",
        "    hin_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_2500.txt\"\n",
        "    hin_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_15000.txt\"\n",
        "    hin_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_30000.txt\"\n",
        "    hin_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_test.txt\"\n",
        "\n",
        "    results = []\n",
        "    results.append(train_and_save(eng_small, eng_test, \"English\", \"small\"))\n",
        "    results.append(train_and_save(eng_med, eng_test, \"English\", \"medium\"))\n",
        "    results.append(train_and_save(eng_large, eng_test, \"English\", \"large\"))\n",
        "\n",
        "    results.append(train_and_save(hin_small, hin_test, \"Hindi\", \"small\"))\n",
        "    results.append(train_and_save(hin_med, hin_test, \"Hindi\", \"medium\"))\n",
        "    results.append(train_and_save(hin_large, hin_test, \"Hindi\", \"large\"))\n",
        "\n",
        "    print(\"\\nFinal Results:\", results)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BdG43gwmJS1",
        "outputId": "e799c7ae-b45e-4104-de27-6b3050c5fcc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Training English small Dataset (Bigram) =====\n",
            "Perplexity: 5036.33\n",
            "Classification - Acc: 0.218, Prec: 0.138, Rec: 0.218, F1: 0.096\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_english_small.pkl\n",
            "\n",
            "===== Training English medium Dataset (Bigram) =====\n",
            "Perplexity: 3188.66\n",
            "Classification - Acc: 0.397, Prec: 0.374, Rec: 0.397, F1: 0.289\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_english_medium.pkl\n",
            "\n",
            "===== Training English large Dataset (Bigram) =====\n",
            "Perplexity: 3366.53\n",
            "Classification - Acc: 0.415, Prec: 0.338, Rec: 0.415, F1: 0.317\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_english_large.pkl\n",
            "\n",
            "===== Training Hindi small Dataset (Bigram) =====\n",
            "Perplexity: 99.37\n",
            "Classification - Acc: 0.298, Prec: 0.544, Rec: 0.298, F1: 0.282\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_hindi_small.pkl\n",
            "\n",
            "===== Training Hindi medium Dataset (Bigram) =====\n",
            "Perplexity: 63.13\n",
            "Classification - Acc: 0.612, Prec: 0.662, Rec: 0.612, F1: 0.570\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_hindi_medium.pkl\n",
            "\n",
            "===== Training Hindi large Dataset (Bigram) =====\n",
            "Perplexity: 54.94\n",
            "Classification - Acc: 0.737, Prec: 0.741, Rec: 0.737, F1: 0.714\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_hindi_large.pkl\n",
            "\n",
            "Final Results: [{'lang': 'English', 'size': 'small', 'perplexity': 5036.332994722976, 'accuracy': 0.21801181102362205, 'precision': 0.13807332021209964, 'recall': 0.21801181102362205, 'f1': 0.09570761945678206}, {'lang': 'English', 'size': 'medium', 'perplexity': 3188.6590699666626, 'accuracy': 0.3971456692913386, 'precision': 0.37439754965577104, 'recall': 0.3971456692913386, 'f1': 0.288610861702526}, {'lang': 'English', 'size': 'large', 'perplexity': 3366.534114667216, 'accuracy': 0.41453412073490814, 'precision': 0.3382263736201442, 'recall': 0.41453412073490814, 'f1': 0.3169310306232349}, {'lang': 'Hindi', 'size': 'small', 'perplexity': 99.36570461935861, 'accuracy': 0.29756666666666665, 'precision': 0.5440924806694916, 'recall': 0.29756666666666665, 'f1': 0.28246461440449305}, {'lang': 'Hindi', 'size': 'medium', 'perplexity': 63.13048489745364, 'accuracy': 0.6122, 'precision': 0.661792484366388, 'recall': 0.6122, 'f1': 0.5698069983406172}, {'lang': 'Hindi', 'size': 'large', 'perplexity': 54.940211840130054, 'accuracy': 0.7365333333333334, 'precision': 0.7414860776062794, 'recall': 0.7365333333333334, 'f1': 0.7139971577182608}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para = \"प्रधानमंत्री नरेंद्र मोदी ने चंद्रयान-3 मिशन में शामिल इसरो के वैज्ञानिकों को संबोधित करते हुए कहा है कि चंद्रमा पर जिस जगह विक्रम लैंडर उतरा उसे शिवशक्ति पॉइंट कहा जाएगा। उन्होंने कहा, स्पेस मिशन्स के टचडाउन पॉइंट को नाम दिए जाने की वैज्ञानिक परंपरा है। चंद्रमा के जिस स्थान पर चंद्रयान-3 उतरा...भारत ने भी उसके नामकरण का फैसला किया है।\"\n",
        "print(predict_genre(para, \"/content/drive/MyDrive/NLP_Assignment1/Bigram_Models/ngram_hindi_large.pkl\", top_k=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxVRWB3bnoWr",
        "outputId": "2c8ea8ff-83da-4b84-bc5b-d0840f76238e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(np.str_('[national, technology]'), 0.9902949665468653), (np.str_('[technology]'), 0.00807527051060882), (np.str_('[politics, national]'), 0.0005170258991057897)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.svm import LinearSVC\n",
        "import torch\n",
        "\n",
        "# -----------------------\n",
        "# Device setup\n",
        "# -----------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -----------------------\n",
        "# Dataset loader\n",
        "# -----------------------\n",
        "def load_dataset(filepath):\n",
        "    data = []\n",
        "    current_label = None\n",
        "    current_text = []\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"'\") and line.count(\"','\") >= 1:\n",
        "                if current_label is not None:\n",
        "                    data.append((current_label, \" \".join(current_text)))\n",
        "                parts = line.split(\"','\", 1)\n",
        "                current_label = parts[0].strip(\"'\")\n",
        "                current_text = [parts[1].rstrip(\"'\")] if len(parts) > 1 else []\n",
        "            else:\n",
        "                current_text.append(line)\n",
        "        if current_label is not None:\n",
        "            data.append((current_label, \" \".join(current_text)))\n",
        "\n",
        "    labels, texts = zip(*data)\n",
        "    return list(labels), list(texts)\n",
        "\n",
        "# Convert comma-separated genres to list\n",
        "def parse_labels(label_str):\n",
        "    return [l.strip() for l in label_str.split(\",\")]\n",
        "\n",
        "# -----------------------\n",
        "# Tokenization\n",
        "# -----------------------\n",
        "def tokenize_text(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", str(text).lower())\n",
        "\n",
        "# -----------------------\n",
        "# Vocabulary + Co-occurrence\n",
        "# -----------------------\n",
        "def build_vocab(texts, min_count=5):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = [w for w, c in counter.items() if c >= min_count]\n",
        "    print(f\"Vocab size after pruning (min_count={min_count}): {len(vocab)}\")\n",
        "    return vocab\n",
        "\n",
        "def build_cooccurrence(texts, vocab, window_size=5, cooc_min=2):\n",
        "    word_to_id = {w: i for i, w in enumerate(vocab)}\n",
        "    cooc = defaultdict(float)\n",
        "    for text in texts:\n",
        "        tokens = tokenize_text(text)\n",
        "        for i, w in enumerate(tokens):\n",
        "            wi = word_to_id.get(w)\n",
        "            if wi is None: continue\n",
        "            start = max(0, i - window_size)\n",
        "            end = min(len(tokens), i + window_size + 1)\n",
        "            for j in range(start, end):\n",
        "                if i == j: continue\n",
        "                wj = word_to_id.get(tokens[j])\n",
        "                if wj is None: continue\n",
        "                cooc[(wi, wj)] += 1.0\n",
        "    # prune\n",
        "    cooc = {k: v for k, v in cooc.items() if v >= cooc_min}\n",
        "    print(f\"Co-occurrence pairs after pruning (min_cooc={cooc_min}): {len(cooc)}\")\n",
        "    return cooc, word_to_id\n",
        "\n",
        "# -----------------------\n",
        "# GloVe model (PyTorch)\n",
        "# -----------------------\n",
        "class GloVeTorch(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, vector_size=100, xmax=100, alpha=0.75):\n",
        "        super().__init__()\n",
        "        self.W = torch.nn.Parameter(torch.randn(vocab_size, vector_size) / math.sqrt(vector_size))\n",
        "        self.W_tilde = torch.nn.Parameter(torch.randn(vocab_size, vector_size) / math.sqrt(vector_size))\n",
        "        self.b = torch.nn.Parameter(torch.zeros(vocab_size))\n",
        "        self.b_tilde = torch.nn.Parameter(torch.zeros(vocab_size))\n",
        "        self.xmax = xmax\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, i_idx, j_idx, x_ij):\n",
        "        w_i = self.W[i_idx]\n",
        "        w_j = self.W_tilde[j_idx]\n",
        "        b_i = self.b[i_idx]\n",
        "        b_j = self.b_tilde[j_idx]\n",
        "        pred = torch.sum(w_i * w_j, dim=1) + b_i + b_j\n",
        "        log_x = torch.log(x_ij)\n",
        "        weight = torch.where(x_ij < self.xmax, (x_ij / self.xmax) ** self.alpha, torch.ones_like(x_ij))\n",
        "        loss = weight * (pred - log_x) ** 2\n",
        "        return torch.mean(loss)\n",
        "\n",
        "# -----------------------\n",
        "# Train GloVe with GPU\n",
        "# -----------------------\n",
        "def train_glove_pytorch(cooc, vocab_size, vector_size=100, epochs=20, lr=0.05, batch_size=50000):\n",
        "    model = GloVeTorch(vocab_size, vector_size).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    i_idx = torch.tensor([k[0] for k in cooc.keys()], device=device, dtype=torch.long)\n",
        "    j_idx = torch.tensor([k[1] for k in cooc.keys()], device=device, dtype=torch.long)\n",
        "    x_ij = torch.tensor([v for v in cooc.values()], device=device, dtype=torch.float)\n",
        "\n",
        "    num_pairs = len(cooc)\n",
        "    for epoch in range(epochs):\n",
        "        perm = torch.randperm(num_pairs)\n",
        "        total_loss = 0.0\n",
        "        for start in range(0, num_pairs, batch_size):\n",
        "            idx = perm[start:start+batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(i_idx[idx], j_idx[idx], x_ij[idx])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(idx)\n",
        "        avg_loss = total_loss / num_pairs\n",
        "        perplexity = math.exp(min(avg_loss, 700))  # prevent overflow\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.2f}, Pseudo-Perplexity: {perplexity:.2f}\")\n",
        "    embeddings = (model.W + model.W_tilde).detach()\n",
        "    return embeddings\n",
        "\n",
        "# -----------------------\n",
        "# Sentence embeddings on GPU\n",
        "# -----------------------\n",
        "def sentence_embeddings_batch(sentences, word_to_id, embeddings_tensor):\n",
        "    vecs = []\n",
        "    for sent in sentences:\n",
        "        tokens = tokenize_text(sent)\n",
        "        ids = [word_to_id[w] for w in tokens if w in word_to_id]\n",
        "        if ids:\n",
        "            vec = embeddings_tensor[ids].mean(dim=0)\n",
        "        else:\n",
        "            vec = torch.zeros(embeddings_tensor.shape[1], device=embeddings_tensor.device)\n",
        "        vecs.append(vec)\n",
        "    return torch.stack(vecs)\n",
        "\n",
        "# -----------------------\n",
        "# Save / Load\n",
        "# -----------------------\n",
        "def save_model(obj, filepath):\n",
        "    with open(filepath, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_model(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# -----------------------\n",
        "# Train + Classifier\n",
        "# -----------------------\n",
        "def train_and_save_glove(train_path, test_path, lang, size, top_k=3):\n",
        "    print(f\"\\n===== Training {lang} {size} Dataset (GloVe PyTorch) =====\")\n",
        "    train_labels, train_texts = load_dataset(train_path)\n",
        "    train_labels = [parse_labels(lbl) for lbl in train_labels]\n",
        "    test_labels, test_texts = load_dataset(test_path)\n",
        "    test_labels = [parse_labels(lbl) for lbl in test_labels]\n",
        "\n",
        "    # Set thresholds and vector size\n",
        "    if size == \"small\":\n",
        "        min_count, min_cooc, vector_size, epochs = 2, 1, 50, 50\n",
        "    elif size == \"medium\":\n",
        "        min_count, min_cooc, vector_size, epochs = 5, 2, 100, 50\n",
        "    else:\n",
        "        min_count, min_cooc, vector_size, epochs = 10, 5, 200, 30\n",
        "\n",
        "    vocab = build_vocab(train_texts, min_count)\n",
        "    cooc, word_to_id = build_cooccurrence(train_texts, vocab, cooc_min=min_cooc)\n",
        "\n",
        "    embeddings = train_glove_pytorch(cooc, len(vocab), vector_size, epochs=epochs, lr=0.05)\n",
        "    embeddings_tensor = embeddings.to(device)\n",
        "\n",
        "    # Sentence embeddings\n",
        "    X_train = sentence_embeddings_batch(train_texts, word_to_id, embeddings_tensor).cpu().numpy()\n",
        "    X_test = sentence_embeddings_batch(test_texts, word_to_id, embeddings_tensor).cpu().numpy()\n",
        "\n",
        "    # Flatten multi-genre labels to first label for classifier (LinearSVC is single-label)\n",
        "    train_labels_single = [lbls[0] for lbls in train_labels]\n",
        "\n",
        "    clf = LinearSVC(class_weight=\"balanced\")\n",
        "    clf.fit(X_train, train_labels_single)\n",
        "\n",
        "    # -----------------------\n",
        "    # Multi-genre-aware evaluation\n",
        "    # -----------------------\n",
        "    scores = clf.decision_function(X_test)\n",
        "    classes = clf.classes_\n",
        "    y_pred_topk = []\n",
        "    for s in scores:\n",
        "        idx = s.argsort()[::-1][:top_k]\n",
        "        y_pred_topk.append([classes[i] for i in idx])\n",
        "\n",
        "    # Accuracy: correct if any predicted genre matches any true genre\n",
        "    correct = 0\n",
        "    for pred_list, true_list in zip(y_pred_topk, test_labels):\n",
        "        if any(p in true_list for p in pred_list):\n",
        "            correct += 1\n",
        "    acc_topk = correct / len(test_labels)\n",
        "    print(f\"Top-{top_k} Multi-genre-aware Accuracy: {acc_topk:.3f}\")\n",
        "\n",
        "    # Save\n",
        "    # save_path = f\"glove_{lang.lower()}_{size}.pkl\"\n",
        "    # save_model({\n",
        "    #     \"embeddings\": embeddings.cpu().numpy(),\n",
        "    #     \"word_to_id\": word_to_id,\n",
        "    #     \"classifier\": clf,\n",
        "    #     \"classes\": classes\n",
        "    # }, save_path)\n",
        "    # print(f\"Model saved at {save_path}\")\n",
        "\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/NLP_Assignment1/Glove_Models\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    save_path = os.path.join(SAVE_DIR, f\"glove_{lang.lower()}_{size}.pkl\")\n",
        "    save_model(\n",
        "    {\n",
        "        \"embeddings\": embeddings.cpu().numpy(),\n",
        "        \"word_to_id\": word_to_id,\n",
        "        \"classifier\": clf,\n",
        "        \"classes\": clf.classes_\n",
        "    },\n",
        "    save_path\n",
        "    )\n",
        "    print(f\"Model saved at {save_path}\")\n",
        "    return {\"lang\": lang, \"size\": size, \"accuracy_topk\": acc_topk}\n",
        "\n",
        "# -----------------------\n",
        "# Predict\n",
        "# -----------------------\n",
        "def predict_genre_glove(paragraph, model_path, top_k=3):\n",
        "    saved = load_model(model_path)\n",
        "    embeddings = torch.tensor(saved[\"embeddings\"], device=device, dtype=torch.float)\n",
        "    word_to_id = saved[\"word_to_id\"]\n",
        "    clf = saved[\"classifier\"]\n",
        "    classes = saved[\"classes\"]\n",
        "    X = sentence_embeddings_batch([paragraph], word_to_id, embeddings).cpu().numpy()\n",
        "\n",
        "    # Top-k predictions\n",
        "    scores = clf.decision_function(X)[0]\n",
        "    idx = scores.argsort()[::-1][:top_k]\n",
        "    top_genres = [classes[i] for i in idx]\n",
        "    return top_genres\n",
        "\n",
        "# -----------------------\n",
        "# Example execution\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    eng_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_2500.txt\"\n",
        "    eng_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_15000.txt\"\n",
        "    eng_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_30000.txt\"\n",
        "    eng_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_test.txt\"\n",
        "\n",
        "    hin_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_2500.txt\"\n",
        "    hin_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_15000.txt\"\n",
        "    hin_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_30000.txt\"\n",
        "    hin_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_test.txt\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Train Hindi datasets (you can enable English similarly)\n",
        "    results.append(train_and_save_glove(hin_small, hin_test, \"Hindi\", \"small\"))\n",
        "    results.append(train_and_save_glove(hin_med, hin_test, \"Hindi\", \"medium\"))\n",
        "    results.append(train_and_save_glove(hin_large, hin_test, \"Hindi\", \"large\"))\n",
        "\n",
        "    print(\"\\nFinal Results:\")\n",
        "    for r in results:\n",
        "        print(r)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvlmSPa-mjMg",
        "outputId": "37a899ea-724d-4491-e357-7463eee237b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "===== Training Hindi small Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=2): 1977\n",
            "Co-occurrence pairs after pruning (min_cooc=1): 149580\n",
            "Epoch 1/50, Loss: 1.24, Pseudo-Perplexity: 3.44\n",
            "Epoch 2/50, Loss: 0.75, Pseudo-Perplexity: 2.11\n",
            "Epoch 3/50, Loss: 0.25, Pseudo-Perplexity: 1.28\n",
            "Epoch 4/50, Loss: 0.22, Pseudo-Perplexity: 1.24\n",
            "Epoch 5/50, Loss: 0.09, Pseudo-Perplexity: 1.10\n",
            "Epoch 6/50, Loss: 0.12, Pseudo-Perplexity: 1.13\n",
            "Epoch 7/50, Loss: 0.10, Pseudo-Perplexity: 1.10\n",
            "Epoch 8/50, Loss: 0.06, Pseudo-Perplexity: 1.06\n",
            "Epoch 9/50, Loss: 0.06, Pseudo-Perplexity: 1.06\n",
            "Epoch 10/50, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Epoch 11/50, Loss: 0.04, Pseudo-Perplexity: 1.05\n",
            "Epoch 12/50, Loss: 0.04, Pseudo-Perplexity: 1.04\n",
            "Epoch 13/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 14/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 15/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 16/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 17/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 18/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 19/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 20/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 21/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 22/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 23/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 24/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 25/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 26/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 27/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 28/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 29/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 30/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 31/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 32/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 33/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 34/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 35/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 36/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 37/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 38/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 39/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 40/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 41/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 42/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 43/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 44/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 45/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 46/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 47/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 48/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 49/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 50/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Top-3 Multi-genre-aware Accuracy: 0.617\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_hindi_small.pkl\n",
            "\n",
            "===== Training Hindi medium Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=5): 2639\n",
            "Co-occurrence pairs after pruning (min_cooc=2): 173897\n",
            "Epoch 1/50, Loss: 4.32, Pseudo-Perplexity: 75.40\n",
            "Epoch 2/50, Loss: 1.20, Pseudo-Perplexity: 3.33\n",
            "Epoch 3/50, Loss: 0.86, Pseudo-Perplexity: 2.37\n",
            "Epoch 4/50, Loss: 0.42, Pseudo-Perplexity: 1.53\n",
            "Epoch 5/50, Loss: 0.30, Pseudo-Perplexity: 1.35\n",
            "Epoch 6/50, Loss: 0.26, Pseudo-Perplexity: 1.30\n",
            "Epoch 7/50, Loss: 0.14, Pseudo-Perplexity: 1.15\n",
            "Epoch 8/50, Loss: 0.17, Pseudo-Perplexity: 1.19\n",
            "Epoch 9/50, Loss: 0.09, Pseudo-Perplexity: 1.10\n",
            "Epoch 10/50, Loss: 0.10, Pseudo-Perplexity: 1.11\n",
            "Epoch 11/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 12/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 13/50, Loss: 0.06, Pseudo-Perplexity: 1.06\n",
            "Epoch 14/50, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Epoch 15/50, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Epoch 16/50, Loss: 0.04, Pseudo-Perplexity: 1.04\n",
            "Epoch 17/50, Loss: 0.04, Pseudo-Perplexity: 1.04\n",
            "Epoch 18/50, Loss: 0.04, Pseudo-Perplexity: 1.04\n",
            "Epoch 19/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 20/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 21/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 22/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 23/50, Loss: 0.02, Pseudo-Perplexity: 1.03\n",
            "Epoch 24/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 25/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 26/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 27/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 28/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 29/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 30/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 31/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 32/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 33/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 34/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 35/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 36/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 37/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 38/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 39/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 40/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 41/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 42/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 43/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 44/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 45/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 46/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 47/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 48/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 49/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 50/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Top-3 Multi-genre-aware Accuracy: 0.707\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_hindi_medium.pkl\n",
            "\n",
            "===== Training Hindi large Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=10): 2631\n",
            "Co-occurrence pairs after pruning (min_cooc=5): 168893\n",
            "Epoch 1/30, Loss: 7.15, Pseudo-Perplexity: 1271.41\n",
            "Epoch 2/30, Loss: 1.60, Pseudo-Perplexity: 4.97\n",
            "Epoch 3/30, Loss: 0.69, Pseudo-Perplexity: 2.00\n",
            "Epoch 4/30, Loss: 0.94, Pseudo-Perplexity: 2.56\n",
            "Epoch 5/30, Loss: 0.45, Pseudo-Perplexity: 1.57\n",
            "Epoch 6/30, Loss: 0.27, Pseudo-Perplexity: 1.31\n",
            "Epoch 7/30, Loss: 0.35, Pseudo-Perplexity: 1.42\n",
            "Epoch 8/30, Loss: 0.17, Pseudo-Perplexity: 1.18\n",
            "Epoch 9/30, Loss: 0.17, Pseudo-Perplexity: 1.18\n",
            "Epoch 10/30, Loss: 0.14, Pseudo-Perplexity: 1.15\n",
            "Epoch 11/30, Loss: 0.10, Pseudo-Perplexity: 1.10\n",
            "Epoch 12/30, Loss: 0.09, Pseudo-Perplexity: 1.09\n",
            "Epoch 13/30, Loss: 0.07, Pseudo-Perplexity: 1.08\n",
            "Epoch 14/30, Loss: 0.06, Pseudo-Perplexity: 1.06\n",
            "Epoch 15/30, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Epoch 16/30, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Epoch 17/30, Loss: 0.04, Pseudo-Perplexity: 1.04\n",
            "Epoch 18/30, Loss: 0.03, Pseudo-Perplexity: 1.04\n",
            "Epoch 19/30, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 20/30, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 21/30, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 22/30, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 23/30, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 24/30, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 25/30, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 26/30, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 27/30, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 28/30, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 29/30, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 30/30, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Top-3 Multi-genre-aware Accuracy: 0.803\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_hindi_large.pkl\n",
            "\n",
            "Final Results:\n",
            "{'lang': 'Hindi', 'size': 'small', 'accuracy_topk': 0.6165433149793346}\n",
            "{'lang': 'Hindi', 'size': 'medium', 'accuracy_topk': 0.7071415821055378}\n",
            "{'lang': 'Hindi', 'size': 'large', 'accuracy_topk': 0.8025182967855329}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prediction\n",
        "para = \"प्रधानमंत्री नरेंद्र मोदी ने चंद्रयान-3 मिशन में शामिल इसरो के वैज्ञानिकों को संबोधित किया।\"\n",
        "print(\"Predicted genres:\", predict_genre_glove(para, \"/content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_hindi_large.pkl\", top_k=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDfeINGe_qx3",
        "outputId": "cacf2e1c-6354-4c57-cfec-e10eff73e4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted genres: [np.str_('[national'), np.str_('[entertainment'), np.str_('[national]')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.svm import LinearSVC\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# -----------------------\n",
        "# Device setup\n",
        "# -----------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# -----------------------\n",
        "# Dataset loader\n",
        "# -----------------------\n",
        "def load_dataset(filepath):\n",
        "    data = []\n",
        "    current_label = None\n",
        "    current_text = []\n",
        "\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith(\"'\") and line.count(\"','\") >= 1:\n",
        "                if current_label is not None:\n",
        "                    data.append((current_label, \" \".join(current_text)))\n",
        "                parts = line.split(\"','\", 1)\n",
        "                current_label = parts[0].strip(\"'\")\n",
        "                current_text = [parts[1].rstrip(\"'\")] if len(parts) > 1 else []\n",
        "            else:\n",
        "                current_text.append(line)\n",
        "        if current_label is not None:\n",
        "            data.append((current_label, \" \".join(current_text)))\n",
        "\n",
        "    labels, texts = zip(*data)\n",
        "    return list(labels), list(texts)\n",
        "\n",
        "# Convert comma-separated genres to list\n",
        "def parse_labels(label_str):\n",
        "    return [l.strip() for l in label_str.split(\",\")]\n",
        "\n",
        "# -----------------------\n",
        "# Tokenization\n",
        "# -----------------------\n",
        "def tokenize_text(text):\n",
        "    return re.findall(r\"\\b\\w+\\b\", str(text).lower())\n",
        "\n",
        "# -----------------------\n",
        "# Vocabulary + Co-occurrence\n",
        "# -----------------------\n",
        "def build_vocab(texts, min_count=5):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(tokenize_text(text))\n",
        "    vocab = [w for w, c in counter.items() if c >= min_count]\n",
        "    print(f\"Vocab size after pruning (min_count={min_count}): {len(vocab)}\")\n",
        "    return vocab\n",
        "\n",
        "def build_cooccurrence(texts, vocab, window_size=5, cooc_min=2):\n",
        "    word_to_id = {w: i for i, w in enumerate(vocab)}\n",
        "    cooc = defaultdict(float)\n",
        "    for text in texts:\n",
        "        tokens = tokenize_text(text)\n",
        "        for i, w in enumerate(tokens):\n",
        "            wi = word_to_id.get(w)\n",
        "            if wi is None: continue\n",
        "            start = max(0, i - window_size)\n",
        "            end = min(len(tokens), i + window_size + 1)\n",
        "            for j in range(start, end):\n",
        "                if i == j: continue\n",
        "                wj = word_to_id.get(tokens[j])\n",
        "                if wj is None: continue\n",
        "                cooc[(wi, wj)] += 1.0\n",
        "    # prune\n",
        "    cooc = {k: v for k, v in cooc.items() if v >= cooc_min}\n",
        "    print(f\"Co-occurrence pairs after pruning (min_cooc={cooc_min}): {len(cooc)}\")\n",
        "    return cooc, word_to_id\n",
        "\n",
        "# -----------------------\n",
        "# GloVe model (PyTorch)\n",
        "# -----------------------\n",
        "class GloVeTorch(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, vector_size=100, xmax=100, alpha=0.75):\n",
        "        super().__init__()\n",
        "        self.W = torch.nn.Parameter(torch.randn(vocab_size, vector_size) / math.sqrt(vector_size))\n",
        "        self.W_tilde = torch.nn.Parameter(torch.randn(vocab_size, vector_size) / math.sqrt(vector_size))\n",
        "        self.b = torch.nn.Parameter(torch.zeros(vocab_size))\n",
        "        self.b_tilde = torch.nn.Parameter(torch.zeros(vocab_size))\n",
        "        self.xmax = xmax\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, i_idx, j_idx, x_ij):\n",
        "        w_i = self.W[i_idx]\n",
        "        w_j = self.W_tilde[j_idx]\n",
        "        b_i = self.b[i_idx]\n",
        "        b_j = self.b_tilde[j_idx]\n",
        "        pred = torch.sum(w_i * w_j, dim=1) + b_i + b_j\n",
        "        log_x = torch.log(x_ij)\n",
        "        weight = torch.where(x_ij < self.xmax, (x_ij / self.xmax) ** self.alpha, torch.ones_like(x_ij))\n",
        "        loss = weight * (pred - log_x) ** 2\n",
        "        return torch.mean(loss)\n",
        "\n",
        "# -----------------------\n",
        "# Train GloVe with GPU\n",
        "# -----------------------\n",
        "def train_glove_pytorch(cooc, vocab_size, vector_size=100, epochs=20, lr=0.05, batch_size=50000):\n",
        "    model = GloVeTorch(vocab_size, vector_size).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    i_idx = torch.tensor([k[0] for k in cooc.keys()], device=device, dtype=torch.long)\n",
        "    j_idx = torch.tensor([k[1] for k in cooc.keys()], device=device, dtype=torch.long)\n",
        "    x_ij = torch.tensor([v for v in cooc.values()], device=device, dtype=torch.float)\n",
        "\n",
        "    num_pairs = len(cooc)\n",
        "    for epoch in range(epochs):\n",
        "        perm = torch.randperm(num_pairs)\n",
        "        total_loss = 0.0\n",
        "        for start in range(0, num_pairs, batch_size):\n",
        "            idx = perm[start:start+batch_size]\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(i_idx[idx], j_idx[idx], x_ij[idx])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * len(idx)\n",
        "        avg_loss = total_loss / num_pairs\n",
        "        perplexity = math.exp(min(avg_loss, 700))  # prevent overflow\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.2f}, Pseudo-Perplexity: {perplexity:.2f}\")\n",
        "    embeddings = (model.W + model.W_tilde).detach()\n",
        "    return embeddings\n",
        "\n",
        "# -----------------------\n",
        "# Sentence embeddings on GPU\n",
        "# -----------------------\n",
        "def sentence_embeddings_batch(sentences, word_to_id, embeddings_tensor):\n",
        "    vecs = []\n",
        "    for sent in sentences:\n",
        "        tokens = tokenize_text(sent)\n",
        "        ids = [word_to_id[w] for w in tokens if w in word_to_id]\n",
        "        if ids:\n",
        "            vec = embeddings_tensor[ids].mean(dim=0)\n",
        "        else:\n",
        "            vec = torch.zeros(embeddings_tensor.shape[1], device=embeddings_tensor.device)\n",
        "        vecs.append(vec)\n",
        "    return torch.stack(vecs)\n",
        "\n",
        "# -----------------------\n",
        "# Save / Load\n",
        "# -----------------------\n",
        "def save_model(obj, filepath):\n",
        "    with open(filepath, \"wb\") as f:\n",
        "        pickle.dump(obj, f)\n",
        "\n",
        "def load_model(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "# -----------------------\n",
        "# Train + Classifier\n",
        "# -----------------------\n",
        "def train_and_save_glove(train_path, test_path, lang, size, top_k=3):\n",
        "    print(f\"\\n===== Training {lang} {size} Dataset (GloVe PyTorch) =====\")\n",
        "    train_labels, train_texts = load_dataset(train_path)\n",
        "    train_labels = [parse_labels(lbl) for lbl in train_labels]\n",
        "    test_labels, test_texts = load_dataset(test_path)\n",
        "    test_labels = [parse_labels(lbl) for lbl in test_labels]\n",
        "\n",
        "    # Set thresholds and vector size\n",
        "    if size == \"small\":\n",
        "        min_count, min_cooc, vector_size, epochs = 2, 1, 50, 50\n",
        "    elif size == \"medium\":\n",
        "        min_count, min_cooc, vector_size, epochs = 5, 2, 100, 50\n",
        "    else:\n",
        "        min_count, min_cooc, vector_size, epochs = 10, 5, 200, 50\n",
        "\n",
        "\n",
        "    vocab = build_vocab(train_texts, min_count)\n",
        "    cooc, word_to_id = build_cooccurrence(train_texts, vocab, cooc_min=min_cooc)\n",
        "\n",
        "    embeddings = train_glove_pytorch(cooc, len(vocab), vector_size, epochs=epochs, lr=0.05)\n",
        "    embeddings_tensor = embeddings.to(device)\n",
        "\n",
        "    # Sentence embeddings\n",
        "    X_train = sentence_embeddings_batch(train_texts, word_to_id, embeddings_tensor).cpu().numpy()\n",
        "    X_test = sentence_embeddings_batch(test_texts, word_to_id, embeddings_tensor).cpu().numpy()\n",
        "\n",
        "    # Flatten multi-genre labels to first label for classifier (LinearSVC is single-label)\n",
        "    train_labels_single = [lbls[0] for lbls in train_labels]\n",
        "\n",
        "    clf = LinearSVC(class_weight=\"balanced\")\n",
        "    clf.fit(X_train, train_labels_single)\n",
        "\n",
        "    # -----------------------\n",
        "    # Multi-genre-aware evaluation\n",
        "    # -----------------------\n",
        "    scores = clf.decision_function(X_test)\n",
        "    classes = clf.classes_\n",
        "    y_pred_topk = []\n",
        "    for s in scores:\n",
        "        idx = s.argsort()[::-1][:top_k]\n",
        "        y_pred_topk.append([classes[i] for i in idx])\n",
        "\n",
        "    # Accuracy: correct if any predicted genre matches any true genre\n",
        "    correct = 0\n",
        "    for pred_list, true_list in zip(y_pred_topk, test_labels):\n",
        "        if any(p in true_list for p in pred_list):\n",
        "            correct += 1\n",
        "    acc_topk = correct / len(test_labels)\n",
        "    print(f\"Top-{top_k} Multi-genre-aware Accuracy: {acc_topk:.3f}\")\n",
        "\n",
        "    # Save\n",
        "    # save_path = f\"glove_{lang.lower()}_{size}.pkl\"\n",
        "    # save_model({\n",
        "    #     \"embeddings\": embeddings.cpu().numpy(),\n",
        "    #     \"word_to_id\": word_to_id,\n",
        "    #     \"classifier\": clf,\n",
        "    #     \"classes\": classes\n",
        "    # }, save_path)\n",
        "    # print(f\"Model saved at {save_path}\")\n",
        "\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/NLP_Assignment1/Glove_Models\"\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    save_path = os.path.join(SAVE_DIR, f\"glove_{lang.lower()}_{size}.pkl\")\n",
        "    save_model(\n",
        "    {\n",
        "        \"embeddings\": embeddings.cpu().numpy(),\n",
        "        \"word_to_id\": word_to_id,\n",
        "        \"classifier\": clf,\n",
        "        \"classes\": clf.classes_\n",
        "    },\n",
        "    save_path\n",
        "    )\n",
        "    print(f\"Model saved at {save_path}\")\n",
        "    return {\"lang\": lang, \"size\": size, \"accuracy_topk\": acc_topk}\n",
        "\n",
        "# -----------------------\n",
        "# Predict\n",
        "# -----------------------\n",
        "def predict_genre_glove(paragraph, model_path, top_k=3):\n",
        "    saved = load_model(model_path)\n",
        "    embeddings = torch.tensor(saved[\"embeddings\"], device=device, dtype=torch.float)\n",
        "    word_to_id = saved[\"word_to_id\"]\n",
        "    clf = saved[\"classifier\"]\n",
        "    classes = saved[\"classes\"]\n",
        "    X = sentence_embeddings_batch([paragraph], word_to_id, embeddings).cpu().numpy()\n",
        "\n",
        "    # Top-k predictions\n",
        "    scores = clf.decision_function(X)[0]\n",
        "    idx = scores.argsort()[::-1][:top_k]\n",
        "    top_genres = [classes[i] for i in idx]\n",
        "    return top_genres\n",
        "\n",
        "# -----------------------\n",
        "# Example execution\n",
        "# -----------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths\n",
        "    eng_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_2500.txt\"\n",
        "    eng_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_15000.txt\"\n",
        "    eng_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_30000.txt\"\n",
        "    eng_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/english/english_test.txt\"\n",
        "\n",
        "    hin_small = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_2500.txt\"\n",
        "    hin_med   = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_15000.txt\"\n",
        "    hin_large = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_30000.txt\"\n",
        "    hin_test  = \"/content/drive/MyDrive/NLP_Assignment1/datasets 2/hindi/hindi_test.txt\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    results.append(train_and_save_glove(eng_small, eng_test, \"English\", \"small\"))\n",
        "    results.append(train_and_save_glove(eng_med, eng_test, \"English\", \"medium\"))\n",
        "    results.append(train_and_save_glove(eng_large, eng_test, \"English\", \"large\"))\n",
        "\n",
        "    # Train Hindi datasets (you can enable English similarly)\n",
        "    # results.append(train_and_save_glove(hin_small, hin_test, \"Hindi\", \"small\"))\n",
        "    # results.append(train_and_save_glove(hin_med, hin_test, \"Hindi\", \"medium\"))\n",
        "    # results.append(train_and_save_glove(hin_large, hin_test, \"Hindi\", \"large\"))\n",
        "\n",
        "    print(\"\\nFinal Results:\")\n",
        "    for r in results:\n",
        "        print(r)\n",
        "\n",
        "    print(\"Predicted genres:\", predict_genre_glove(para, \"/content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_hindi_large.pkl\", top_k=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tW0yti4GnO-j",
        "outputId": "13668b86-109b-4808-858e-b27e1de24c21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "===== Training English small Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=2): 17758\n",
            "Co-occurrence pairs after pruning (min_cooc=1): 2174061\n",
            "Epoch 1/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 2/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 3/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 4/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 5/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 6/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 7/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 8/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 9/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 10/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 11/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 12/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 13/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 14/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 15/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 16/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 17/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 18/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 19/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 20/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 21/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 22/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 23/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 24/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 25/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 26/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 27/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 28/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 29/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 30/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 31/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 32/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 33/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 34/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 35/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 36/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 37/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 38/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 39/50, Loss: 0.03, Pseudo-Perplexity: 1.03\n",
            "Epoch 40/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 41/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 42/50, Loss: 0.02, Pseudo-Perplexity: 1.02\n",
            "Epoch 43/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 44/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 45/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 46/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 47/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 48/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 49/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Epoch 50/50, Loss: 0.01, Pseudo-Perplexity: 1.01\n",
            "Top-3 Multi-genre-aware Accuracy: 0.265\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_english_small.pkl\n",
            "\n",
            "===== Training English medium Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=5): 37097\n",
            "Co-occurrence pairs after pruning (min_cooc=2): 4693912\n",
            "Epoch 1/50, Loss: 0.19, Pseudo-Perplexity: 1.21\n",
            "Epoch 2/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 3/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 4/50, Loss: 0.08, Pseudo-Perplexity: 1.09\n",
            "Epoch 5/50, Loss: 0.10, Pseudo-Perplexity: 1.11\n",
            "Epoch 6/50, Loss: 0.11, Pseudo-Perplexity: 1.11\n",
            "Epoch 7/50, Loss: 0.11, Pseudo-Perplexity: 1.12\n",
            "Epoch 8/50, Loss: 0.12, Pseudo-Perplexity: 1.13\n",
            "Epoch 9/50, Loss: 0.14, Pseudo-Perplexity: 1.15\n",
            "Epoch 10/50, Loss: 0.17, Pseudo-Perplexity: 1.18\n",
            "Epoch 11/50, Loss: 0.21, Pseudo-Perplexity: 1.23\n",
            "Epoch 12/50, Loss: 0.27, Pseudo-Perplexity: 1.31\n",
            "Epoch 13/50, Loss: 0.32, Pseudo-Perplexity: 1.38\n",
            "Epoch 14/50, Loss: 0.34, Pseudo-Perplexity: 1.40\n",
            "Epoch 15/50, Loss: 0.30, Pseudo-Perplexity: 1.35\n",
            "Epoch 16/50, Loss: 0.25, Pseudo-Perplexity: 1.28\n",
            "Epoch 17/50, Loss: 0.20, Pseudo-Perplexity: 1.22\n",
            "Epoch 18/50, Loss: 0.16, Pseudo-Perplexity: 1.18\n",
            "Epoch 19/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 20/50, Loss: 0.11, Pseudo-Perplexity: 1.11\n",
            "Epoch 21/50, Loss: 0.09, Pseudo-Perplexity: 1.10\n",
            "Epoch 22/50, Loss: 0.08, Pseudo-Perplexity: 1.09\n",
            "Epoch 23/50, Loss: 0.08, Pseudo-Perplexity: 1.08\n",
            "Epoch 24/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 25/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 26/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 27/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 28/50, Loss: 0.07, Pseudo-Perplexity: 1.07\n",
            "Epoch 29/50, Loss: 0.08, Pseudo-Perplexity: 1.08\n",
            "Epoch 30/50, Loss: 0.08, Pseudo-Perplexity: 1.08\n",
            "Epoch 31/50, Loss: 0.09, Pseudo-Perplexity: 1.09\n",
            "Epoch 32/50, Loss: 0.11, Pseudo-Perplexity: 1.11\n",
            "Epoch 33/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 34/50, Loss: 0.16, Pseudo-Perplexity: 1.17\n",
            "Epoch 35/50, Loss: 0.20, Pseudo-Perplexity: 1.22\n",
            "Epoch 36/50, Loss: 0.27, Pseudo-Perplexity: 1.31\n",
            "Epoch 37/50, Loss: 0.37, Pseudo-Perplexity: 1.45\n",
            "Epoch 38/50, Loss: 0.50, Pseudo-Perplexity: 1.64\n",
            "Epoch 39/50, Loss: 0.64, Pseudo-Perplexity: 1.90\n",
            "Epoch 40/50, Loss: 0.76, Pseudo-Perplexity: 2.13\n",
            "Epoch 41/50, Loss: 0.78, Pseudo-Perplexity: 2.18\n",
            "Epoch 42/50, Loss: 0.70, Pseudo-Perplexity: 2.01\n",
            "Epoch 43/50, Loss: 0.56, Pseudo-Perplexity: 1.75\n",
            "Epoch 44/50, Loss: 0.39, Pseudo-Perplexity: 1.47\n",
            "Epoch 45/50, Loss: 0.25, Pseudo-Perplexity: 1.29\n",
            "Epoch 46/50, Loss: 0.17, Pseudo-Perplexity: 1.19\n",
            "Epoch 47/50, Loss: 0.11, Pseudo-Perplexity: 1.12\n",
            "Epoch 48/50, Loss: 0.08, Pseudo-Perplexity: 1.09\n",
            "Epoch 49/50, Loss: 0.06, Pseudo-Perplexity: 1.06\n",
            "Epoch 50/50, Loss: 0.05, Pseudo-Perplexity: 1.05\n",
            "Top-3 Multi-genre-aware Accuracy: 0.257\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_english_medium.pkl\n",
            "\n",
            "===== Training English large Dataset (GloVe PyTorch) =====\n",
            "Vocab size after pruning (min_count=10): 36646\n",
            "Co-occurrence pairs after pruning (min_cooc=5): 2116116\n",
            "Epoch 1/50, Loss: 0.83, Pseudo-Perplexity: 2.30\n",
            "Epoch 2/50, Loss: 0.24, Pseudo-Perplexity: 1.27\n",
            "Epoch 3/50, Loss: 0.26, Pseudo-Perplexity: 1.30\n",
            "Epoch 4/50, Loss: 0.23, Pseudo-Perplexity: 1.26\n",
            "Epoch 5/50, Loss: 0.24, Pseudo-Perplexity: 1.28\n",
            "Epoch 6/50, Loss: 0.17, Pseudo-Perplexity: 1.19\n",
            "Epoch 7/50, Loss: 0.15, Pseudo-Perplexity: 1.17\n",
            "Epoch 8/50, Loss: 0.12, Pseudo-Perplexity: 1.13\n",
            "Epoch 9/50, Loss: 0.12, Pseudo-Perplexity: 1.12\n",
            "Epoch 10/50, Loss: 0.11, Pseudo-Perplexity: 1.12\n",
            "Epoch 11/50, Loss: 0.11, Pseudo-Perplexity: 1.12\n",
            "Epoch 12/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 13/50, Loss: 0.16, Pseudo-Perplexity: 1.17\n",
            "Epoch 14/50, Loss: 0.23, Pseudo-Perplexity: 1.25\n",
            "Epoch 15/50, Loss: 0.37, Pseudo-Perplexity: 1.44\n",
            "Epoch 16/50, Loss: 0.67, Pseudo-Perplexity: 1.95\n",
            "Epoch 17/50, Loss: 1.31, Pseudo-Perplexity: 3.69\n",
            "Epoch 18/50, Loss: 2.66, Pseudo-Perplexity: 14.33\n",
            "Epoch 19/50, Loss: 4.87, Pseudo-Perplexity: 129.82\n",
            "Epoch 20/50, Loss: 6.92, Pseudo-Perplexity: 1016.72\n",
            "Epoch 21/50, Loss: 7.01, Pseudo-Perplexity: 1111.32\n",
            "Epoch 22/50, Loss: 5.63, Pseudo-Perplexity: 278.83\n",
            "Epoch 23/50, Loss: 3.54, Pseudo-Perplexity: 34.58\n",
            "Epoch 24/50, Loss: 2.05, Pseudo-Perplexity: 7.75\n",
            "Epoch 25/50, Loss: 1.26, Pseudo-Perplexity: 3.52\n",
            "Epoch 26/50, Loss: 0.95, Pseudo-Perplexity: 2.58\n",
            "Epoch 27/50, Loss: 0.64, Pseudo-Perplexity: 1.90\n",
            "Epoch 28/50, Loss: 0.48, Pseudo-Perplexity: 1.62\n",
            "Epoch 29/50, Loss: 0.48, Pseudo-Perplexity: 1.61\n",
            "Epoch 30/50, Loss: 0.36, Pseudo-Perplexity: 1.43\n",
            "Epoch 31/50, Loss: 0.31, Pseudo-Perplexity: 1.36\n",
            "Epoch 32/50, Loss: 0.27, Pseudo-Perplexity: 1.31\n",
            "Epoch 33/50, Loss: 0.28, Pseudo-Perplexity: 1.32\n",
            "Epoch 34/50, Loss: 0.24, Pseudo-Perplexity: 1.27\n",
            "Epoch 35/50, Loss: 0.24, Pseudo-Perplexity: 1.28\n",
            "Epoch 36/50, Loss: 0.16, Pseudo-Perplexity: 1.17\n",
            "Epoch 37/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 38/50, Loss: 0.15, Pseudo-Perplexity: 1.16\n",
            "Epoch 39/50, Loss: 0.17, Pseudo-Perplexity: 1.19\n",
            "Epoch 40/50, Loss: 0.10, Pseudo-Perplexity: 1.11\n",
            "Epoch 41/50, Loss: 0.11, Pseudo-Perplexity: 1.11\n",
            "Epoch 42/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 43/50, Loss: 0.16, Pseudo-Perplexity: 1.17\n",
            "Epoch 44/50, Loss: 0.13, Pseudo-Perplexity: 1.14\n",
            "Epoch 45/50, Loss: 0.15, Pseudo-Perplexity: 1.17\n",
            "Epoch 46/50, Loss: 0.14, Pseudo-Perplexity: 1.15\n",
            "Epoch 47/50, Loss: 0.15, Pseudo-Perplexity: 1.16\n",
            "Epoch 48/50, Loss: 0.16, Pseudo-Perplexity: 1.18\n",
            "Epoch 49/50, Loss: 0.21, Pseudo-Perplexity: 1.24\n",
            "Epoch 50/50, Loss: 0.17, Pseudo-Perplexity: 1.18\n",
            "Top-3 Multi-genre-aware Accuracy: 0.210\n",
            "Model saved at /content/drive/MyDrive/NLP_Assignment1/Glove_Models/glove_english_large.pkl\n",
            "\n",
            "Final Results:\n",
            "{'lang': 'English', 'size': 'small', 'accuracy_topk': 0.2651262505955217}\n",
            "{'lang': 'English', 'size': 'medium', 'accuracy_topk': 0.2569477528982055}\n",
            "{'lang': 'English', 'size': 'large', 'accuracy_topk': 0.20978243608067335}\n",
            "Predicted genres: [np.str_('[national'), np.str_('[entertainment'), np.str_('[national]')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Example prediction\n",
        "para = \"toy story\"\n",
        "print(\"Predicted genres:\", predict_genre_glove(para, \"glove_english_medium.pkl\", top_k=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGgRxBnTq0pz",
        "outputId": "676f86ab-a2a2-42bc-ed05-1bd9a7d11680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted genres: [np.str_('16\\xa0mm film'), np.str_('operetta'), np.str_('sci-fi drama')]\n"
          ]
        }
      ]
    }
  ]
}